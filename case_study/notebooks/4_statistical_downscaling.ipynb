{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c897ee",
   "metadata": {},
   "source": [
    "# 4. Downscaling de Dados Locais e Dados do CMIP6\n",
    "\n",
    "```python\n",
    "Esse caderno tem como objetivo a obtenção da precipitação futura de dados locais \n",
    "para os pontos definidos nos GCMs do CMIP6 a partir de predição.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1867920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, \n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50625fc1",
   "metadata": {},
   "source": [
    "## 4.1. Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b688c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de se vai ocorrer ou não a geração de bases de dados\n",
    "databases_generate = True\n",
    "\n",
    "# Definição de se vai ocorrer ou não o a geração e o uso do método IDW\n",
    "idw_method = True\n",
    "idw_generate = False\n",
    "\n",
    "# Tipo de base de dados local utilizada ('sum' ou 'max')\n",
    "database_type = 'sum'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ce24e",
   "metadata": {},
   "source": [
    "## 4.2. Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd782b8c",
   "metadata": {},
   "source": [
    "### 4.2.1. Predição a partir de Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ed126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicao_por_ml(df: pd.DataFrame,\n",
    "                    col_de_treino: list[str],\n",
    "                    var_de_predicao: str,\n",
    "                    ano_X: int):\n",
    "\n",
    "    # Definição dos modelos\n",
    "    models = [\n",
    "\n",
    "        (\"ExtraTrees\", ExtraTreesRegressor(\n",
    "            n_estimators=200, \n",
    "            max_depth=20, \n",
    "            max_features=2,\n",
    "            min_samples_split=2, \n",
    "            min_samples_leaf=1, \n",
    "            random_state=7\n",
    "        )),\n",
    "        \n",
    "        (\"RandomForest\", RandomForestRegressor(\n",
    "            n_estimators=300, \n",
    "            max_depth=25, \n",
    "            max_features=2, \n",
    "            min_samples_split=2, \n",
    "            min_samples_leaf=1, \n",
    "            random_state=7\n",
    "        )),\n",
    "\n",
    "        (\"KNeighbors\", KNeighborsRegressor(\n",
    "            n_neighbors=7, \n",
    "            weights='distance', \n",
    "            algorithm='auto'\n",
    "        )),\n",
    "        \n",
    "        (\"GradientBoosting\", GradientBoostingRegressor(\n",
    "            n_estimators=200, \n",
    "            learning_rate=0.05, \n",
    "            max_depth=5, \n",
    "            subsample=0.8, \n",
    "            random_state=7\n",
    "        )),\n",
    "        \n",
    "        (\"LinearRegression\", LinearRegression(\n",
    "            fit_intercept=True, \n",
    "            positive=False\n",
    "        ))\n",
    "    \n",
    "    ]\n",
    "\n",
    "    # Lista de métricas por modelo\n",
    "    metrics = [[0, 0] for _ in models]\n",
    "\n",
    "    df_treino = df[df['ano'] <= ano_X].copy()\n",
    "    df_teste  = df[df['ano']  > ano_X].copy()\n",
    "\n",
    "    X_train = df_treino[col_de_treino]\n",
    "    y_train = df_treino[var_de_predicao]\n",
    "\n",
    "    X_test = df_teste[col_de_treino]\n",
    "    y_test = df_teste[var_de_predicao]\n",
    "\n",
    "    # Treinar e avaliar modelos\n",
    "    for j, (nome, modelo) in enumerate(models):\n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        metrics[j][0] = r2_score(y_test, y_pred)                     # R²\n",
    "        metrics[j][1] = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE\n",
    "\n",
    "    # Verificando melhor Modelo a partir de r2\n",
    "    best_model = (0, '', '')\n",
    "\n",
    "    print('Verificação de Modelos:\\n')\n",
    "\n",
    "    for i, (nome, modelo) in enumerate(models):\n",
    "\n",
    "        r2, rmse = metrics[i][0], metrics[i][1]\n",
    "\n",
    "        if best_model[0] < r2:\n",
    "            best_model = r2, nome, modelo\n",
    "\n",
    "        print(f'Modelo: {nome[:10]:<10} \\t R²: {r2:.8f} \\t RMSE: {rmse:.8f}')\n",
    "\n",
    "    print(f'\\nO melhor modelo de ML para a base de dados é: {best_model[1]}.')\n",
    "\n",
    "    return best_model[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f140e",
   "metadata": {},
   "source": [
    "### 4.2.2. Função para Limeza de Terminal e Células"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fc97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear():\n",
    "    '''\n",
    "    Função para limpar terminal ou célula\n",
    "    '''\n",
    "\n",
    "    # Limpando terminal\n",
    "    os.system('cls')\n",
    "\n",
    "    # Limpando célula\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d055b3",
   "metadata": {},
   "source": [
    "### 4.2.3. Interpolação a partir de Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7dae822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolacao_por_ml(df: pd.DataFrame,\n",
    "                        col_de_treino: list[str],\n",
    "                        var_de_predicao: str,\n",
    "                        var_de_pontos: str,\n",
    "                        n_de_teste: int):\n",
    "\n",
    "    # Obtendo pontos únicos\n",
    "    pontos_unicos = df[var_de_pontos].unique()\n",
    "\n",
    "    # Definição dos modelos\n",
    "    models = [\n",
    "\n",
    "        (\"ExtraTrees\", ExtraTreesRegressor(\n",
    "            n_estimators=15, \n",
    "            max_depth=20, \n",
    "            max_features=2,\n",
    "            min_samples_split=2, \n",
    "            min_samples_leaf=1, \n",
    "            random_state=7\n",
    "        )),\n",
    "        \n",
    "        (\"RandomForest\", RandomForestRegressor(\n",
    "            n_estimators=15, \n",
    "            max_depth=25, \n",
    "            max_features=2, \n",
    "            min_samples_split=2, \n",
    "            min_samples_leaf=1, \n",
    "            random_state=7\n",
    "        )),\n",
    "\n",
    "        (\"KNeighbors\", KNeighborsRegressor(\n",
    "            n_neighbors=7, \n",
    "            weights='distance', \n",
    "            algorithm='auto'\n",
    "        )),\n",
    "        \n",
    "        (\"GradientBoosting\", GradientBoostingRegressor(\n",
    "            n_estimators=200, \n",
    "            learning_rate=0.05, \n",
    "            max_depth=5, \n",
    "            subsample=0.8, \n",
    "            random_state=7\n",
    "        )),\n",
    "        \n",
    "        (\"LinearRegression\", LinearRegression(\n",
    "            fit_intercept=True, \n",
    "            positive=False\n",
    "        ))\n",
    "    \n",
    "    ]\n",
    "\n",
    "    # Defininção de lista de métricas\n",
    "    metrics = []\n",
    "    for i in range(len(models)):\n",
    "        metrics.append([[], []])\n",
    "\n",
    "    for i in range(n_de_teste):\n",
    "\n",
    "        # Embaralha os pontos únicos\n",
    "        np.random.shuffle(pontos_unicos)\n",
    "\n",
    "        # Dividindo em 70% treino e 30% teste\n",
    "        split_idx = int(len(pontos_unicos) * 0.8)\n",
    "        pontos_treino = set(pontos_unicos[:split_idx])\n",
    "        pontos_teste = set(pontos_unicos[split_idx:])\n",
    "\n",
    "        # Criando DataFrames de treino e teste\n",
    "        df_treino = df[df[var_de_pontos].isin(pontos_treino)].copy()\n",
    "        df_teste = df[df[var_de_pontos].isin(pontos_teste)].copy()\n",
    "\n",
    "        # Definindo features (X) e variável alvo (y)\n",
    "        X_train = df_treino[col_de_treino]\n",
    "        y_train = df_treino[var_de_predicao]\n",
    "\n",
    "        X_test = df_teste[col_de_treino]\n",
    "        y_test = df_teste[var_de_predicao]\n",
    "\n",
    "        # Treinar e avaliar cada modelo\n",
    "        for j in range(len(models)):\n",
    "            models[j][1].fit(X_train, y_train)                                 # Treinamento\n",
    "            y_pred = models[j][1].predict(X_test)                              # Previsão\n",
    "            metrics[j][0].append(r2_score(y_test, y_pred))                     # R²\n",
    "            metrics[j][1].append(np.sqrt(mean_squared_error(y_test, y_pred)))  # RMSE\n",
    "\n",
    "    # Verificando melhor Modelo a partir de r2\n",
    "    best_model = (0, '', '')\n",
    "\n",
    "    print('Verificação de Modelos:\\n')\n",
    "\n",
    "    for i in range(len(metrics)):\n",
    "\n",
    "        r2, rmse = np.mean(metrics[i][0]), np.mean(metrics[i][1])\n",
    "\n",
    "        if best_model[0] < r2:\n",
    "            best_model = r2, models[i][0], models[i][1]\n",
    "\n",
    "        print(f'Modelo: {models[i][0][:3]} \\t R²: {r2:.4f} \\t RMSE: {rmse:.4f}')\n",
    "    \n",
    "    print(f'\\nO melhor modelo de ML para a base de dados é: {best_model[1]}.')\n",
    "\n",
    "    return best_model[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322fbd1b",
   "metadata": {},
   "source": [
    "### 4.2.4. Função que Adiciona coluna IDW à Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "243b880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def porcentagem_em_barra(valor_atual: int, \n",
    "                         valor_total: int) -> str:\n",
    "    \"\"\"\n",
    "    Gerador de barra de porcentagem a partir de valor atual e total.\n",
    "    \"\"\"\n",
    "    \n",
    "    porcentagem = 100 * (valor_atual / valor_total)\n",
    "\n",
    "    completo   = '-' * (int(porcentagem))\n",
    "    incompleto = '_' * (100 - int(porcentagem))\n",
    "\n",
    "    situacao = f'[{completo}{incompleto}] {porcentagem:.2f}% ({valor_atual} de {valor_total})'\n",
    "\n",
    "    return situacao\n",
    "\n",
    "def vizinhos_proximos(lat: float,\n",
    "                      lon: float,\n",
    "                      lat_lon: list[str],\n",
    "                      n_vizinhos: int = 5):\n",
    "    \"\"\"\n",
    "    Gerador de lista de pontos vizinhos próximos de determinado ponto.\n",
    "\n",
    "    Args:\n",
    "        lat (float): Latitude do ponto principal;\n",
    "        lon (float): Logitude do ponto principal;\n",
    "        lat_lon (list[str]): Lista com latitudes e longitudes de pontos próximos ao ponto principal;\n",
    "        n_vizinhos (int, optional): Números de pontos vizinhos ao ponto principal a se estimar.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de n pontos mais próximos ao ponto principal.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lista para armazenar tuplas (string_original, distancia)\n",
    "    distancias = []\n",
    "\n",
    "    for ponto_str in lat_lon:\n",
    "        lat_p, lon_p = map(float, ponto_str.split(\";\"))\n",
    "        dist = np.linalg.norm(np.array([lat, lon]) - np.array([lat_p, lon_p]))\n",
    "        distancias.append((ponto_str, dist))\n",
    "    \n",
    "    # Ordena pela menor distância\n",
    "    distancias_ordenadas = sorted(distancias, key=lambda x: x[1])\n",
    "    \n",
    "    # Pega os n vizinhos mais próximos (ignorando o primeiro se for o próprio ponto)\n",
    "    vizinhos = [p[0] for p in distancias_ordenadas if p[1] != 0][:n_vizinhos]\n",
    "    \n",
    "    return vizinhos\n",
    "\n",
    "def interpolacao_por_idw(df: pd.DataFrame,\n",
    "                         var_de_predicao: str,\n",
    "                         var_de_anos: str,\n",
    "                         var_de_meses: str,\n",
    "                         var_de_pontos: str,\n",
    "                         pontos: str = 'all',\n",
    "                         progresso: bool = True,\n",
    "                         constante: int = 2,\n",
    "                         n_vizinhos: int = 5) -> list:\n",
    "    '''\n",
    "    Interpola dados de séries temporais a partir do método IDW, e cria uma coluna para tal\n",
    "    '''\n",
    "    \n",
    "    # Definindo nova coluna para o IDW\n",
    "    df.loc[:, 'IDW'] = np.nan\n",
    "    \n",
    "    # Obtendo pontos únicos\n",
    "    if pontos == 'all':\n",
    "        pontos_unicos = df[var_de_pontos].unique()\n",
    "    else:\n",
    "        pontos_unicos = [pontos]\n",
    "\n",
    "    # Varendo pontos únicos\n",
    "    for i, ponto in enumerate(pontos_unicos):\n",
    "\n",
    "        if progresso == True:\n",
    "        \n",
    "            # Ponto em cálculo\n",
    "            print(porcentagem_em_barra(i+1, len(pontos_unicos)))\n",
    "\n",
    "        lat, lon = map(float, ponto.split(\";\"))\n",
    "\n",
    "        # Obtendo anos únicos\n",
    "        anos_unicos = df[df[var_de_pontos] == ponto][var_de_anos].unique()\n",
    "        \n",
    "        # Varendo anos únicos dos pontos únicos\n",
    "        for ano in anos_unicos:\n",
    "            \n",
    "            # Obtendo meses únicos\n",
    "            meses_unicos = df[(df[var_de_pontos] == ponto) & \n",
    "                              (df[var_de_anos] == ano)][var_de_meses].unique()\n",
    "\n",
    "            # Varrendo meses únicos dos anos únicos dos pontos únicos\n",
    "            for mes in meses_unicos:\n",
    "\n",
    "                # Filtrando pontos unicos que possuem mesmo mes e ano que o ponto em varredura\n",
    "                pontos_unicos_filtrados = df[(df[var_de_anos] == ano) &\n",
    "                                             (df[var_de_meses] == mes)][var_de_pontos].unique()\n",
    "                \n",
    "                # Obtendo pontos vizinhos mais próximos do ponto em varredura\n",
    "                vizinhos = vizinhos_proximos(lat, lon, pontos_unicos_filtrados, n_vizinhos)\n",
    "\n",
    "                # Definindo variáveis para calcular IDW                \n",
    "                dividendo = divisor = 0\n",
    "\n",
    "                for ponto_vizinho in vizinhos:\n",
    "\n",
    "                    lat_vizinha, lon_vizinha = map(float, ponto_vizinho.split(\";\"))\n",
    "                    \n",
    "                    distancia = ((lat - lat_vizinha)**2 + (lon - lon_vizinha)**2)**(1/2)\n",
    "\n",
    "                    variavel = df.loc[(df[var_de_pontos] == ponto_vizinho) & \n",
    "                                      (df[var_de_anos] == ano) & \n",
    "                                      (df[var_de_meses] == mes), var_de_predicao]\n",
    "                    \n",
    "                    if not variavel.empty:\n",
    "                        valor = variavel.iloc[0]\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    dividendo += valor / (distancia**constante)\n",
    "\n",
    "                    divisor += 1 / (distancia**constante)\n",
    "\n",
    "                if divisor == 0:\n",
    "                    idw = np.nan\n",
    "                else:\n",
    "                    idw = dividendo / divisor\n",
    "\n",
    "                idx = df.loc[(df[var_de_pontos] == ponto) & \n",
    "                             (df[var_de_anos] == ano) &\n",
    "                             (df[var_de_meses] == mes), 'IDW'].index[0]\n",
    "                \n",
    "                df.at[idx, 'IDW'] = idw\n",
    "                              \n",
    "        clear()\n",
    "\n",
    "    df['IDW'] = df['IDW'].fillna(df['IDW'].mean())\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1db9db",
   "metadata": {},
   "source": [
    "## 4.3. CNRM-CM6-1HR\n",
    "\n",
    "Redução de escala de dados locais e dados experimentais do CMIP6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7f7de",
   "metadata": {},
   "source": [
    "### 4.3.1. Coluna IDW para dados CNRM-CM6-1HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a15e485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Informações do GCM:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64200 entries, 0 to 64199\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   lat     64200 non-null  float64\n",
      " 1   lon     64200 non-null  float64\n",
      " 2   ano     64200 non-null  int64  \n",
      " 3   mes     64200 non-null  int64  \n",
      " 4   pr      64200 non-null  float64\n",
      " 5   pnt     64200 non-null  object \n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Definindo base de dados de GCM\n",
    "df_cnrm_cm6_1hr = pd.read_csv(\n",
    "    f\"../datas/interim/1.3.2_cmip6_database_create/pr_day_CNRM-CM6-1-HR_ssp585_r1i1p1f2_gr_19940101-21001231_{database_type}.csv\"\n",
    ")\n",
    "\n",
    "# Padronizando valores de longitude\n",
    "df_cnrm_cm6_1hr[\"lon\"] = df_cnrm_cm6_1hr[\"lon\"] - 360\n",
    "\n",
    "# Adicionando coluna de pontos\n",
    "df_cnrm_cm6_1hr['pnt'] = df_cnrm_cm6_1hr[\"lat\"].astype(str) + \";\" + df_cnrm_cm6_1hr[\"lon\"].astype(str)\n",
    "\n",
    "# Caso não tenha a coluna IDW nas \"colunas_de_interesse\", calcula-se o IDW\n",
    "if idw_method == True:\n",
    "\n",
    "    if idw_generate == True:  # 115m 33.8s\n",
    "\n",
    "        df_cnrm_cm6_1hr = interpolacao_por_idw(df_cnrm_cm6_1hr, \"pr\", \"ano\", \"mes\", \"pnt\")\n",
    "        df_cnrm_cm6_1hr.to_csv(f'../datas/interim/4.3.1_cmip6_with_idw/pr_day_CNRM-CM6-1-HR_ssp585_r1i1p1f2_gr_19940101-21001231_{database_type}_idw.csv')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df_cnrm_cm6_1hr = pd.read_csv(f'../datas/interim/4.3.1_cmip6_with_idw/pr_day_CNRM-CM6-1-HR_ssp585_r1i1p1f2_gr_19940101-21001231_{database_type}_idw.csv')\n",
    "\n",
    "# Definindo colunas de interesse\n",
    "colunas_gcm = ['lat', 'lon', 'ano', 'mes', 'pr', 'pnt']\n",
    "\n",
    "# Restringindo base de dados às colunas de interesse\n",
    "df_cnrm_cm6_1hr = df_cnrm_cm6_1hr[colunas_gcm].copy()\n",
    "\n",
    "# Visualizando Bases de Dados do GCM\n",
    "print('- Informações do GCM:')\n",
    "print(df_cnrm_cm6_1hr.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee1664",
   "metadata": {},
   "source": [
    "### 4.3.2. Criação de Bases de Dados de Redução de Escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4186b7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   lat       18000 non-null  float64\n",
      " 1   lon       18000 non-null  float64\n",
      " 2   ano       18000 non-null  int64  \n",
      " 3   mes       18000 non-null  int64  \n",
      " 4   pr_local  18000 non-null  float64\n",
      " 5   pnt       18000 non-null  object \n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 843.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Importando base de dados\n",
    "df_aesa_to_cnrm_cm6_1hr = pd.read_csv(f'../datas/interim/3.3.3_aesa_interpolated_to_cmip6/aesa_to_cnrm_cm6_1hr_{database_type}_interpolated.csv')\n",
    "\n",
    "# Definindo colunas de interesse\n",
    "colunas_local = ['lat', 'lon', 'ano', 'mes', 'pr_local', 'pnt']\n",
    "\n",
    "# Adicionando coluna de pontos\n",
    "df_aesa_to_cnrm_cm6_1hr['pnt'] = df_aesa_to_cnrm_cm6_1hr[\"lat\"].astype(str) + \";\" + df_aesa_to_cnrm_cm6_1hr[\"lon\"].astype(str)\n",
    "\n",
    "# Restringindo base de dados às colunas de interesse\n",
    "df_aesa_to_cnrm_cm6_1hr = df_aesa_to_cnrm_cm6_1hr[colunas_local].copy()\n",
    "\n",
    "# Observando informações da base de dados\n",
    "df_aesa_to_cnrm_cm6_1hr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5971b401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64200 entries, 0 to 64199\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   lat       64200 non-null  float64\n",
      " 1   lon       64200 non-null  float64\n",
      " 2   ano       64200 non-null  int64  \n",
      " 3   mes       64200 non-null  int64  \n",
      " 4   pr_local  18000 non-null  float64\n",
      " 5   pnt       64200 non-null  object \n",
      " 6   pr        64200 non-null  float64\n",
      "dtypes: float64(4), int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fazendo o merge com base em 'pnt', 'ano' e 'mes' para base de dados única\n",
    "df_aesa_to_cnrm_cm6_1hr = df_aesa_to_cnrm_cm6_1hr.merge(df_cnrm_cm6_1hr, on=['pnt', 'ano', 'mes', 'lat', 'lon'], how='outer')\n",
    "\n",
    "# Salvando nova base de dados\n",
    "df_aesa_to_cnrm_cm6_1hr.to_csv(f'../datas/interim/4.3.2_create_downscaling_database/aesa_to_cnrm_cm6_1hr_{database_type}_downscaling.csv')\n",
    "\n",
    "# Informações da base de dados única\n",
    "df_aesa_to_cnrm_cm6_1hr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ad727",
   "metadata": {},
   "source": [
    "### 4.3.3. Configurações para Predição em Base de Dados de Redução de Escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "299edfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64200 entries, 0 to 64199\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       64200 non-null  int64  \n",
      " 1   lat              64200 non-null  float64\n",
      " 2   lon              64200 non-null  float64\n",
      " 3   ano              64200 non-null  int64  \n",
      " 4   mes              64200 non-null  int64  \n",
      " 5   pr_local         18000 non-null  float64\n",
      " 6   pnt              64200 non-null  object \n",
      " 7   pr               64200 non-null  float64\n",
      " 8   pr_mes_anterior  64200 non-null  float64\n",
      " 9   pr_acum_6m       64200 non-null  float64\n",
      " 10  cluster          64200 non-null  int32  \n",
      "dtypes: float64(6), int32(1), int64(3), object(1)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Abrindo base de dados para configuração\n",
    "df_aesa_to_cnrm_cm6_1hr = pd.read_csv(f'../datas/interim/4.3.2_create_downscaling_database/aesa_to_cnrm_cm6_1hr_{database_type}_downscaling.csv')\n",
    "\n",
    "# Adicionando coluna de atraso de um mes da precipitação\n",
    "df_aesa_to_cnrm_cm6_1hr['pr_mes_anterior'] = df_aesa_to_cnrm_cm6_1hr.sort_values(by=['pnt', 'ano', 'mes']).groupby('pnt')['pr'].shift(1)\n",
    "df_aesa_to_cnrm_cm6_1hr['pr_mes_anterior'] = df_aesa_to_cnrm_cm6_1hr['pr_mes_anterior'].fillna(df_aesa_to_cnrm_cm6_1hr['pr_mes_anterior'].mean())\n",
    "\n",
    "# Adicionando coluna de atraso de acumulado de seis meses de precipitações anteriores\n",
    "df_aesa_to_cnrm_cm6_1hr['pr_acum_6m'] = df_aesa_to_cnrm_cm6_1hr.sort_values(['pnt', 'ano', 'mes']).groupby('pnt')['pr'].rolling(window=6).sum().reset_index(0, drop=True)\n",
    "df_aesa_to_cnrm_cm6_1hr['pr_acum_6m'] = df_aesa_to_cnrm_cm6_1hr['pr_acum_6m'].fillna(df_aesa_to_cnrm_cm6_1hr['pr_acum_6m'].mean())\n",
    "\n",
    "# Adicionando coluna de agrupamento de dados\n",
    "df_coords = df_aesa_to_cnrm_cm6_1hr[['lat', 'lon']].drop_duplicates()\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(df_coords)\n",
    "df_coords['cluster'] = kmeans.labels_\n",
    "df_aesa_to_cnrm_cm6_1hr = df_aesa_to_cnrm_cm6_1hr.merge(df_coords, on=['lat', 'lon'], how='left')\n",
    "\n",
    "# Salvando nova base de dados gerada\n",
    "df_aesa_to_cnrm_cm6_1hr.to_csv(f'../datas/interim/4.3.3_finish_downscaling_database/aesa_to_cnrm_cm6_1hr_{database_type}_downscaling_complete.csv')\n",
    "\n",
    "# Limpando avisos\n",
    "clear()\n",
    "\n",
    "# Informações da base de dados com novas features\n",
    "df_aesa_to_cnrm_cm6_1hr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746116c",
   "metadata": {},
   "source": [
    "### 4.3.4. Base de Dados de Redução de Escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf6f871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificação de Modelos:\n",
      "\n",
      "Modelo: ExtraTrees \t R²: 0.59100460 \t RMSE: 56.28908754\n",
      "Modelo: RandomFore \t R²: 0.59114112 \t RMSE: 56.27969184\n",
      "Modelo: KNeighbors \t R²: 0.57439228 \t RMSE: 57.42086658\n",
      "Modelo: GradientBo \t R²: 0.59980941 \t RMSE: 55.67989769\n",
      "Modelo: LinearRegr \t R²: 0.37759311 \t RMSE: 69.43879713\n",
      "\n",
      "O melhor modelo de ML para a base de dados é: GradientBoosting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
       "                          random_state=7, subsample=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
       "                          random_state=7, subsample=0.8)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
       "                          random_state=7, subsample=0.8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Abrindo base de dados para predição\n",
    "df_aesa_to_cnrm_cm6_1hr.to_csv(f'../datas/interim/4.3.3_finish_downscaling_database/aesa_to_cnrm_cm6_1hr_{database_type}_downscaling_complete.csv')\n",
    "\n",
    "# Colunas X e y\n",
    "X_col, y_col = ['pr', 'pr_acum_6m', 'pr_mes_anterior', 'cluster', 'ano', 'mes', 'lat', 'lon'], \"pr_local\"\n",
    "\n",
    "# Definindo ano que separará o treino e a predição\n",
    "ano_X = 2017\n",
    "\n",
    "# Supondo que sua função de predição já esteja definida:\n",
    "model = predicao_por_ml(df_aesa_to_cnrm_cm6_1hr[df_aesa_to_cnrm_cm6_1hr['ano'] <= 2023], X_col, y_col, ano_X)\n",
    "\n",
    "# Definindo features (X) e variável alvo (y)\n",
    "X = df_aesa_to_cnrm_cm6_1hr[df_aesa_to_cnrm_cm6_1hr['ano'] <= 2023][X_col].copy()\n",
    "y = df_aesa_to_cnrm_cm6_1hr[df_aesa_to_cnrm_cm6_1hr['ano'] <= 2023][y_col].copy()\n",
    "\n",
    "# Treinamento\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e064f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18000 entries, 0 to 63275\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       18000 non-null  int64  \n",
      " 1   lat              18000 non-null  float64\n",
      " 2   lon              18000 non-null  float64\n",
      " 3   ano              18000 non-null  int64  \n",
      " 4   mes              18000 non-null  int64  \n",
      " 5   pr_local         18000 non-null  float64\n",
      " 6   pnt              18000 non-null  object \n",
      " 7   pr               18000 non-null  float64\n",
      " 8   pr_mes_anterior  18000 non-null  float64\n",
      " 9   pr_acum_6m       18000 non-null  float64\n",
      " 10  cluster          18000 non-null  int32  \n",
      "dtypes: float64(6), int32(1), int64(3), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_aesa_to_cnrm_cm6_1hr[df_aesa_to_cnrm_cm6_1hr['ano'] <= 2023].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59ef41f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64200 entries, 0 to 64199\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       64200 non-null  int64  \n",
      " 1   lat              64200 non-null  float64\n",
      " 2   lon              64200 non-null  float64\n",
      " 3   ano              64200 non-null  int64  \n",
      " 4   mes              64200 non-null  int64  \n",
      " 5   pr_local         64200 non-null  float64\n",
      " 6   pnt              64200 non-null  object \n",
      " 7   pr               64200 non-null  float64\n",
      " 8   pr_mes_anterior  64200 non-null  float64\n",
      " 9   pr_acum_6m       64200 non-null  float64\n",
      " 10  cluster          64200 non-null  int32  \n",
      "dtypes: float64(6), int32(1), int64(3), object(1)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Previsão dos valores de 'pr' com o modelo treinado\n",
    "pr_local = model.predict(df_aesa_to_cnrm_cm6_1hr[df_aesa_to_cnrm_cm6_1hr['ano'] > 2023][X_col])\n",
    "\n",
    "# Adicionando a nova coluna 'pr' ao DataFrame\n",
    "df_aesa_to_cnrm_cm6_1hr.loc[df_aesa_to_cnrm_cm6_1hr[y_col].isnull(), y_col] = pr_local\n",
    "\n",
    "df_aesa_to_cnrm_cm6_1hr.to_csv(f'../datas/processed/4.3.4_downscaling_database/aesa_to_cnrm_cm6_1hr_{database_type}_downscaling_database.csv')\n",
    "\n",
    "# Informações da base de dados predita\n",
    "df_aesa_to_cnrm_cm6_1hr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc804a13",
   "metadata": {},
   "source": [
    "### 4.3.5. Geração de Modelo Preditivo Final de Interpolação de Base de Dados de Redução de Escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f45cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificação de Modelos:\n",
      "\n",
      "Modelo: Ext \t R²: 0.9324 \t RMSE: 17.4166\n",
      "Modelo: Ran \t R²: 0.9234 \t RMSE: 18.5338\n",
      "Modelo: KNe \t R²: 0.9322 \t RMSE: 17.4450\n",
      "Modelo: Gra \t R²: 0.8810 \t RMSE: 23.1106\n",
      "Modelo: Lin \t R²: 0.3478 \t RMSE: 54.0957\n",
      "\n",
      "O melhor modelo de ML para a base de dados é: ExtraTrees.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/aesa_to_cnrm_cm6_1hr_sum_downscaling_database.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aesa_to_cnrm_cm6_1hr.to_csv(f'../datas/processed/4.3.4_downscaling_database/aesa_to_cnrm_cm6_1hr_{database_type}_downscaling_database.csv')\n",
    "\n",
    "# Colunas X e y\n",
    "X_col, y_col = ['ano', 'mes', 'lat', 'lon'], \"pr_local\"\n",
    "\n",
    "# Escolhendo melhor modelo preditivo\n",
    "model = interpolacao_por_ml(df_aesa_to_cnrm_cm6_1hr, X_col, y_col, \"pnt\", 1)\n",
    "\n",
    "# Definindo features (X) e variável alvo (y)\n",
    "X = df_aesa_to_cnrm_cm6_1hr[X_col].copy()\n",
    "y = df_aesa_to_cnrm_cm6_1hr[y_col].copy()\n",
    "\n",
    "# Treinamento\n",
    "model.fit(X, y)\n",
    "\n",
    "# Salvando o modelo\n",
    "joblib.dump(model, f'../models/aesa_to_cnrm_cm6_1hr_{database_type}_downscaling_database.joblib', compress=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
