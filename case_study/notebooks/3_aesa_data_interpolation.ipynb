{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd4f9542",
   "metadata": {},
   "source": [
    "# 3. Espacialização de Dados Locais para Pontos do CMIP6\n",
    "\n",
    "```python\n",
    "Esse caderno tem como objetivo a obtenção da precipitação de dados locais \n",
    "para os pontos definidos nos GCMs do CMIP6 a partir de interpolação espacial.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b45bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor\n",
    ")\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd9789",
   "metadata": {},
   "source": [
    "## 3.1 Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f094f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de se vai ocorrer ou não a geração de bases de dados\n",
    "databases_generate = True\n",
    "\n",
    "# Definição de se vai ocorrer ou não o a geração e o uso do método IDW\n",
    "idw_method = True\n",
    "idw_generate = False\n",
    "\n",
    "# Tipo de base de dados local utilizada ('sum' ou 'max')\n",
    "database_type = 'sum'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73232c",
   "metadata": {},
   "source": [
    "## 3.2 Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f405034d",
   "metadata": {},
   "source": [
    "### 3.1.1. Função para Limeza de Terminal e Células"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0db8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear():\n",
    "    '''\n",
    "    Função para limpar terminal ou célula\n",
    "    '''\n",
    "\n",
    "    # Limpando terminal\n",
    "    # os.system('cls')\n",
    "\n",
    "    # Limpando célula\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f245d",
   "metadata": {},
   "source": [
    "### 3.1.2. Função que Adiciona coluna IDW à Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d44ddef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def porcentagem_em_barra(valor_atual: int,\n",
    "                         valor_total: int) -> str:\n",
    "    \"\"\"\n",
    "    Gerador de barra de porcentagem a partir de valor atual e total.\n",
    "    \"\"\"\n",
    "\n",
    "    porcentagem = 100 * (valor_atual / valor_total)\n",
    "\n",
    "    completo   = '━' * (int(porcentagem))\n",
    "    incompleto = '╺' * (100 - int(porcentagem))\n",
    "\n",
    "    situacao = f'[{completo}{incompleto}] {porcentagem:.2f}% ({valor_atual} de {valor_total})'\n",
    "\n",
    "    return situacao\n",
    "\n",
    "def idw_interpolation(target_point, neighbors, values, const=2):\n",
    "    weights = []\n",
    "    for pt in neighbors:\n",
    "        dist = geodesic(target_point, pt).meters\n",
    "        if dist == 0:\n",
    "            continue  # Evita usar o próprio ponto\n",
    "        weights.append(1 / (dist ** const))\n",
    "    weights = np.array(weights)\n",
    "    values = np.array(values)\n",
    "    return np.sum(weights * values) / np.sum(weights) if np.sum(weights) > 0 else np.nan\n",
    "\n",
    "def calcular_precipitacao_idw(df: pd.DataFrame,\n",
    "                               var_de_interpolacao: str,\n",
    "                               var_de_latitude: str,\n",
    "                               var_de_longitude: str,\n",
    "                               var_de_anos: str,\n",
    "                               var_de_meses: str,\n",
    "                               n_vizinhos: int = 10,\n",
    "                               const: int = 2) -> pd.DataFrame:\n",
    "\n",
    "    df_resultado = df.copy()\n",
    "    df_resultado[\"IDW\"] = np.nan  # nova coluna para os resultados\n",
    "\n",
    "    total = len(df_resultado)\n",
    "    for i, idx in enumerate(df_resultado.index):\n",
    "\n",
    "        row = df_resultado.loc[idx]\n",
    "        ano, mes, lat, lon = row[var_de_anos], row[var_de_meses], row[var_de_latitude], row[var_de_longitude]\n",
    "        target_point = (lat, lon)\n",
    "\n",
    "        # Candidatos com mesma data, excluindo a própria linha\n",
    "        candidatos = df_resultado[(df_resultado[var_de_anos] == ano) &\n",
    "                                  (df_resultado[var_de_meses] == mes) &\n",
    "                                  (df_resultado.index != idx)].copy()\n",
    "\n",
    "        if candidatos.empty:\n",
    "            continue\n",
    "\n",
    "        # Calcular distâncias\n",
    "        candidatos['distancia'] = candidatos.apply(\n",
    "            lambda r: geodesic(target_point, (r[var_de_latitude], r[var_de_longitude])).meters, axis=1\n",
    "        )\n",
    "\n",
    "        # Selecionar os vizinhos mais próximos\n",
    "        vizinhos = candidatos.nsmallest(n_vizinhos, 'distancia')\n",
    "\n",
    "        if not vizinhos.empty:\n",
    "            viz_points = list(zip(vizinhos[var_de_latitude], vizinhos[var_de_longitude]))\n",
    "            viz_values = vizinhos[var_de_interpolacao].tolist()\n",
    "\n",
    "            interpolado = idw_interpolation(target_point, viz_points, viz_values, const)\n",
    "            df_resultado.at[idx, \"IDW\"] = interpolado\n",
    "\n",
    "        # Barra de progresso a cada 10 registros\n",
    "        if (i + 1) % 10 == 0 or (i + 1) == total:\n",
    "            clear()\n",
    "            print(porcentagem_em_barra(i + 1, total))\n",
    "\n",
    "    return df_resultado\n",
    "\n",
    "def preencher_precipitacao_idw(df: pd.DataFrame,\n",
    "                               var_de_interpolacao: str,\n",
    "                               var_de_latitude: str,\n",
    "                               var_de_longitude: str,\n",
    "                               var_de_anos: str,\n",
    "                               var_de_meses: str,\n",
    "                               n_vizinhos: int = 10,\n",
    "                               const: int = 2) -> pd.DataFrame:\n",
    "\n",
    "    df_resultado = df.copy()\n",
    "\n",
    "    # Iterar sobre os índices com valores faltantes\n",
    "    missing_indices = df_resultado[df_resultado[var_de_interpolacao].isna()].index\n",
    "\n",
    "    valor_atual, valor_total = 1, len(missing_indices)\n",
    "\n",
    "    for idx in missing_indices:\n",
    "\n",
    "        row = df_resultado.loc[idx]\n",
    "        ano, mes, lat, lon = row[var_de_anos], row[var_de_meses], row[var_de_latitude], row[var_de_longitude]\n",
    "        target_point = (lat, lon)\n",
    "\n",
    "        # Filtrar pontos com mesma data e precipitação conhecida\n",
    "        filtro = (df_resultado[var_de_anos] == ano) & (df_resultado[var_de_meses] == mes) & df_resultado[var_de_interpolacao].notna()\n",
    "        candidatos = df_resultado[filtro].copy()\n",
    "\n",
    "        # Calcular distâncias\n",
    "        candidatos['distancia'] = candidatos.apply(lambda r: geodesic(target_point, (r[var_de_latitude], r[var_de_longitude])).meters, axis=1)\n",
    "\n",
    "        # Selecionar os pontos mais próximos\n",
    "        vizinhos = candidatos.nsmallest(n_vizinhos, 'distancia')\n",
    "\n",
    "        if not vizinhos.empty:\n",
    "            viz_points = list(zip(vizinhos[var_de_latitude], vizinhos[var_de_longitude]))\n",
    "            viz_values = vizinhos[var_de_interpolacao].tolist()\n",
    "\n",
    "            # Aplicar IDW\n",
    "            interpolado = idw_interpolation(target_point, viz_points, viz_values, const)\n",
    "            df_resultado.at[idx, var_de_interpolacao] = interpolado\n",
    "\n",
    "        if valor_atual % 10 == 0 or valor_atual == valor_total:\n",
    "            clear()\n",
    "            print(porcentagem_em_barra(valor_atual, valor_total))\n",
    "\n",
    "        valor_atual += 1\n",
    "\n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6709bccb",
   "metadata": {},
   "source": [
    "### 3.1.3. Interpolação a partir de Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60e8b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolacao_por_ml(df: pd.DataFrame,\n",
    "                        col_de_treino: list[str],\n",
    "                        var_de_predicao: str,\n",
    "                        var_de_pontos: str,\n",
    "                        n_de_teste: int):\n",
    "\n",
    "    # Obtendo pontos únicos\n",
    "    pontos_unicos = df[var_de_pontos].unique()\n",
    "\n",
    "    # Definição dos modelos\n",
    "    models = [\n",
    "\n",
    "        (\"ExtraTrees\", ExtraTreesRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=20,\n",
    "            max_features=2,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            random_state=7\n",
    "        )),\n",
    "\n",
    "        (\"RandomForest\", RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=25,\n",
    "            max_features=2,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            random_state=7\n",
    "        )),\n",
    "\n",
    "        (\"KNeighbors\", KNeighborsRegressor(\n",
    "            n_neighbors=7,\n",
    "            weights='distance',\n",
    "            algorithm='auto'\n",
    "        )),\n",
    "\n",
    "        (\"GradientBoosting\", GradientBoostingRegressor(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            subsample=0.8,\n",
    "            random_state=7\n",
    "        )),\n",
    "\n",
    "        # (\"LinearRegression\", LinearRegression(\n",
    "        #     fit_intercept=True,\n",
    "        #     positive=False\n",
    "        # ))\n",
    "\n",
    "    ]\n",
    "\n",
    "    # Defininção de lista de métricas\n",
    "    metrics = []\n",
    "    for i in range(len(models)):\n",
    "        metrics.append([[], []])\n",
    "\n",
    "    for i in range(n_de_teste):\n",
    "\n",
    "        # Embaralha os pontos únicos\n",
    "        np.random.shuffle(pontos_unicos)\n",
    "\n",
    "        # Dividindo em 70% treino e 30% teste\n",
    "        split_idx = int(len(pontos_unicos) * 0.8)\n",
    "        pontos_treino = set(pontos_unicos[:split_idx])\n",
    "        pontos_teste = set(pontos_unicos[split_idx:])\n",
    "\n",
    "        # Criando DataFrames de treino e teste\n",
    "        df_treino = df[df[var_de_pontos].isin(pontos_treino)].copy()\n",
    "        df_teste = df[df[var_de_pontos].isin(pontos_teste)].copy()\n",
    "\n",
    "        # Definindo features (X) e variável alvo (y)\n",
    "        X_train = df_treino[col_de_treino]\n",
    "        y_train = df_treino[var_de_predicao]\n",
    "\n",
    "        X_test = df_teste[col_de_treino]\n",
    "        y_test = df_teste[var_de_predicao]\n",
    "\n",
    "        # Treinar e avaliar cada modelo\n",
    "        for j in range(len(models)):\n",
    "            models[j][1].fit(X_train, y_train)                                 # Treinamento\n",
    "            y_pred = models[j][1].predict(X_test)                              # Previsão\n",
    "            metrics[j][0].append(r2_score(y_test, y_pred))                     # R²\n",
    "            metrics[j][1].append(np.sqrt(mean_squared_error(y_test, y_pred)))  # RMSE\n",
    "\n",
    "    # Verificando melhor Modelo a partir de r2\n",
    "    best_model = (0, '', '')\n",
    "\n",
    "    print('Verificação de Modelos:\\n')\n",
    "\n",
    "    for i in range(len(metrics)):\n",
    "\n",
    "        r2, rmse = np.mean(metrics[i][0]), np.mean(metrics[i][1])\n",
    "\n",
    "        if best_model[0] < r2:\n",
    "            best_model = r2, models[i][0], models[i][1]\n",
    "\n",
    "        print(f'Modelo: {models[i][0][:3]} \\t R²: {r2:.4f} \\t RMSE: {rmse:.4f}')\n",
    "\n",
    "    print(f'\\nO melhor modelo de ML para a base de dados é: {best_model[1]}.')\n",
    "\n",
    "    return best_model[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96757be9",
   "metadata": {},
   "source": [
    "### 3.1.4. Interpolação a partir de Modelo de Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b87debf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolacao_por_cnn(df: pd.DataFrame,\n",
    "                         col_de_treino: list[str],\n",
    "                         var_de_predicao: str,\n",
    "                         var_de_pontos: str,\n",
    "                         n_de_teste: int):\n",
    "\n",
    "    # Pontos únicos\n",
    "    pontos_unicos = df[var_de_pontos].unique()\n",
    "\n",
    "    # Listas para métricas\n",
    "    r2_list = []\n",
    "    rmse_list = []\n",
    "\n",
    "    for i in range(n_de_teste):\n",
    "\n",
    "        np.random.shuffle(pontos_unicos)\n",
    "        split_idx = int(len(pontos_unicos) * 0.8)\n",
    "\n",
    "        pontos_treino = set(pontos_unicos[:split_idx])\n",
    "        pontos_teste = set(pontos_unicos[split_idx:])\n",
    "\n",
    "        df_treino = df[df[var_de_pontos].isin(pontos_treino)].copy()\n",
    "        df_teste = df[df[var_de_pontos].isin(pontos_teste)].copy()\n",
    "\n",
    "        # Definindo X e y\n",
    "        X_train = df_treino[col_de_treino].values\n",
    "        y_train = df_treino[var_de_predicao].values\n",
    "\n",
    "        X_test = df_teste[col_de_treino].values\n",
    "        y_test = df_teste[var_de_predicao].values\n",
    "\n",
    "        # Redimensionar para 3D: (samples, timesteps=1, features)\n",
    "        X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "        # Limpar sessão anterior (importante em loops com Keras)\n",
    "        clear_session()\n",
    "\n",
    "        # Criando modelo CNN\n",
    "        cnn = Sequential([\n",
    "            Input(shape=(1, X_train.shape[2])),\n",
    "            Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "            MaxPooling1D(1),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "\n",
    "        cnn.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mse'])\n",
    "\n",
    "        # Treinamento\n",
    "        cnn.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
    "\n",
    "        # Previsão e avaliação\n",
    "        y_pred = cnn.predict(X_test).flatten()\n",
    "\n",
    "        r2_list.append(r2_score(y_test, y_pred))\n",
    "        rmse_list.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    # Resultados finais\n",
    "    print(f\"\\nCNN \\t Média R²: {np.mean(r2_list):.4f} \\t Média RMSE: {np.mean(rmse_list):.4f}\")\n",
    "\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed6cfe3",
   "metadata": {},
   "source": [
    "### 3.1.5. Preenchimento para Serie Temporal Completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_temporal_series(df: pd.DataFrame,\n",
    "                             lat_col: str,\n",
    "                             lon_col: str,\n",
    "                             anos: list) -> pd.DataFrame:\n",
    "    '''\n",
    "    Preenchimento de datas faltantes em séries temporais\n",
    "    '''\n",
    "\n",
    "    # Obtendo pontos de lat lon únicos\n",
    "    df_pontos_unicos = df[[lat_col, lon_col]].drop_duplicates().reset_index().drop(columns=[\"index\"])\n",
    "\n",
    "    # Obtendo meses e anos da base de dados\n",
    "    df_anos_meses = pd.DataFrame([(ano, mes) for ano in anos for mes in range(1, 13)], columns=[\"ano\", \"mes\"])\n",
    "\n",
    "    # Fazendo produto cartesiano entre pontos e anos/meses\n",
    "    df_pontos_unicos['key'] = 1\n",
    "    df_anos_meses['key'] = 1\n",
    "\n",
    "    # Unindo pontos e anos/meses\n",
    "    df_expandido = pd.merge(df_pontos_unicos, df_anos_meses, on='key').drop(columns='key')\n",
    "\n",
    "    # Cria um DataFrame vazio para armazenar os dados expandidos\n",
    "    return df_expandido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bcb420",
   "metadata": {},
   "source": [
    "## 3.2. Coluna IDW para dados da AESA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f513bf8",
   "metadata": {},
   "source": [
    "### 3.2.1. Configurando Bases de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49e267a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━] 100.00% (87120 de 87120)\n",
      "- Informações Locais:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87120 entries, 0 to 87119\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  87120 non-null  int64  \n",
      " 1   lat         87120 non-null  float64\n",
      " 2   lon         87120 non-null  float64\n",
      " 3   ano         87120 non-null  int64  \n",
      " 4   mes         87120 non-null  int64  \n",
      " 5   pr_local    87120 non-null  float64\n",
      " 6   IDW         87120 non-null  float64\n",
      "dtypes: float64(4), int64(3)\n",
      "memory usage: 4.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Base de dados local de acumulados\n",
    "df_aesa = pd.read_csv(\n",
    "    f\"../datas/interim/2.3.1_aesa_database_create/aesa_1994-2023_mon_{database_type}.csv\"\n",
    ")\n",
    "\n",
    "# Caso não tenha a coluna IDW nas \"colunas_de_interesse\", calcula-se o IDW\n",
    "if idw_method == True:\n",
    "\n",
    "    if idw_generate == True:  # 50m 54.6s\n",
    "\n",
    "        # Local\n",
    "        df_aesa = calcular_precipitacao_idw(df_aesa, \"pr_local\", \"lat\", \"lon\", \"ano\", \"mes\")\n",
    "        df_aesa[['lat', 'lon',\n",
    "                 'ano', 'mes',\n",
    "                 'IDW', 'pr_local'\n",
    "        ]].to_csv(f'../datas/interim/3.2.1_aesa_with_idw/aesa_1994-2023_mon_{database_type}_idw.csv')\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Local\n",
    "        df_aesa = pd.read_csv(f'../datas/interim/3.2.1_aesa_with_idw/aesa_1994-2023_mon_{database_type}_idw.csv')\n",
    "\n",
    "# Visualizando Bases de Dados Locais\n",
    "print('- Informações Locais:')\n",
    "print(df_aesa.info())\n",
    "# grafico_de_pontos(df_aesa, \"lat\", \"lon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862258f5",
   "metadata": {},
   "source": [
    "## 3.3. Base de Dados Local para Predição\n",
    "\n",
    "```python\n",
    "O processo consiste em criar uma base de dados com os mesmos \n",
    "pontos da base de dados do GCM, para que assim se possa realizar \n",
    "a interpolação da precipitação local para esses pontos.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9afb457",
   "metadata": {},
   "source": [
    "### 3.3.1. Configurando Base de Dados Local para Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "949ad7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   lat     18000 non-null  float64\n",
      " 1   lon     18000 non-null  float64\n",
      " 2   ano     18000 non-null  int64  \n",
      " 3   mes     18000 non-null  int64  \n",
      "dtypes: float64(2), int64(2)\n",
      "memory usage: 562.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Geração ou abertura de base de dados gerada\n",
    "if databases_generate == True:\n",
    "\n",
    "    # Definindo base de dados de GCM\n",
    "    df_cnrm_cm6_1hr = pd.read_csv(\n",
    "        f\"../datas/interim/1.3.2_cmip6_database_create/pr_day_CNRM-CM6-1-HR_ssp585_r1i1p1f2_gr_19940101-21001231_{database_type}.csv\"\n",
    "    )\n",
    "\n",
    "    # Definindo base de dados\n",
    "    df_aesa_to_cnrm_cm6_1hr = complete_temporal_series(df_cnrm_cm6_1hr, 'lat', 'lon', [i for i in range(1994, 2024)])\n",
    "\n",
    "    # Cria uma coluna \"pnt\" que combina latitude e longitude como string separada por ponto e vírgula\n",
    "    # df_aesa_to_cnrm_cm6_1hr['pnt'] = df_aesa_to_cnrm_cm6_1hr[\"lat\"].astype(str) + \";\" + df_aesa_to_cnrm_cm6_1hr[\"lon\"].astype(str)\n",
    "\n",
    "    # Exportando base de dados gerada\n",
    "    df_aesa_to_cnrm_cm6_1hr.to_csv(f'../datas/interim/3.3.1_aesa_in_cmip6_points/aesa_to_cnrm_cm6_1hr_{database_type}.csv')\n",
    "\n",
    "else:\n",
    "\n",
    "    # Abrindo base de dados\n",
    "    df_aesa_to_cnrm_cm6_1hr = pd.read_csv(f'../datas/interim/3.3.1_aesa_in_cmip6_points/aesa_to_cnrm_cm6_1hr_{database_type}.csv')\n",
    "\n",
    "# Informaões da base de dados gerada\n",
    "df_aesa_to_cnrm_cm6_1hr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23e461",
   "metadata": {},
   "source": [
    "### 3.3.2. Configurando Base de Dados Local para Predição com IDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04979478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━] 100.00% (18000 de 18000)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18000 entries, 0 to 104399\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   lat     18000 non-null  float64\n",
      " 1   lon     18000 non-null  float64\n",
      " 2   ano     18000 non-null  int64  \n",
      " 3   mes     18000 non-null  int64  \n",
      " 4   IDW     18000 non-null  float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 843.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Caso não tenha a coluna IDW nas \"colunas_de_interesse\", calcula-se o IDW\n",
    "if idw_method == True:\n",
    "\n",
    "    if idw_generate == True:  # 25m 35.1s\n",
    "\n",
    "        df_temp = pd.merge(df_aesa_to_cnrm_cm6_1hr, df_aesa[['lat', 'lon', 'ano', 'mes', 'pr_local']],\n",
    "                            on=['lat', 'lon', 'ano', 'mes'],\n",
    "                            how='outer')\n",
    "\n",
    "        indices_com_nulos = df_temp[df_temp.isnull().any(axis=1)].index\n",
    "\n",
    "        df_temp = preencher_precipitacao_idw(df_temp, \"pr_local\", \"lat\", \"lon\", \"ano\", \"mes\")\n",
    "\n",
    "        df_temp = df_temp.loc[indices_com_nulos]\n",
    "\n",
    "        df_temp = df_temp.rename(columns={'pr_local': 'IDW'})\n",
    "\n",
    "        df_temp.to_csv(f'../datas/interim/3.3.2_aesa_in_cmip6_points_with_idw/aesa_to_cnrm_cm6_1hr_{database_type}_idw.csv')\n",
    "\n",
    "        df_aesa_to_cnrm_cm6_1hr = df_temp.copy()\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Abrindo base de dados\n",
    "        df_aesa_to_cnrm_cm6_1hr = pd.read_csv(f'../datas/interim/3.3.2_aesa_in_cmip6_points_with_idw/aesa_to_cnrm_cm6_1hr_{database_type}_idw.csv')\n",
    "\n",
    "# Informaões da base de dados gerada\n",
    "df_aesa_to_cnrm_cm6_1hr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc13927",
   "metadata": {},
   "source": [
    "#### 3.3.3. Configurando Modelo Preditivo de Interpolação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6a464f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificação de Modelos:\n",
      "\n",
      "Modelo: Ext \t R²: 0.8941 \t RMSE: 27.8195\n",
      "Modelo: Ran \t R²: 0.8911 \t RMSE: 28.2154\n",
      "Modelo: KNe \t R²: 0.8810 \t RMSE: 29.4910\n",
      "Modelo: Gra \t R²: 0.8949 \t RMSE: 27.7203\n",
      "\n",
      "O melhor modelo de ML para a base de dados é: GradientBoosting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
       "                          random_state=7, subsample=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
       "                          random_state=7, subsample=0.8)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
       "                          random_state=7, subsample=0.8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo colunas para treino\n",
    "if idw_method == True:\n",
    "    columns_X = [\"lat\", \"lon\", \"ano\", \"mes\", \"IDW\"]\n",
    "else:\n",
    "    columns_X = [\"lat\", \"lon\", \"ano\", \"mes\"]\n",
    "\n",
    "# Definindo pontos únicos\n",
    "df_aesa['pnt'] = df_aesa[\"lat\"].astype(str) + \";\" + df_aesa[\"lon\"].astype(str)\n",
    "\n",
    "# Escolhendo melhor modelo preditivo de ML\n",
    "model = interpolacao_por_ml(df_aesa, columns_X, \"pr_local\", \"pnt\", 5)\n",
    "\n",
    "# # Escolhendo melhor modelo preditivo de DL\n",
    "# model = interpolacao_por_cnn(df_aesa, columns_X, \"pr_local\", \"pnt\", 5)\n",
    "\n",
    "# Definindo features (X) e variável alvo (y)\n",
    "X = df_aesa[columns_X].copy()\n",
    "y = df_aesa[\"pr_local\"].copy()\n",
    "\n",
    "# Treinamento\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a14df54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18000 entries, 0 to 104399\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   lat       18000 non-null  float64\n",
      " 1   lon       18000 non-null  float64\n",
      " 2   ano       18000 non-null  int64  \n",
      " 3   mes       18000 non-null  int64  \n",
      " 4   pr_local  18000 non-null  float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 843.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Previsão dos valores de 'pr_local' com o modelo treinado\n",
    "pr_local = model.predict(df_aesa_to_cnrm_cm6_1hr[columns_X])\n",
    "\n",
    "# Colunas do Modelo\n",
    "columns = ['lat', 'lon', 'ano', 'mes', 'pr_local']\n",
    "\n",
    "# Adicionando a nova coluna 'pr_local' ao DataFrame\n",
    "df_aesa_to_cnrm_cm6_1hr['pr_local'] = pr_local\n",
    "\n",
    "# Salvando dados preditos\n",
    "df_aesa_to_cnrm_cm6_1hr[columns].to_csv(f'../datas/interim/3.3.3_aesa_interpolated_to_cmip6/aesa_to_cnrm_cm6_1hr_{database_type}_interpolated.csv')\n",
    "\n",
    "# Exibindo as primeiras linhas para verificar\n",
    "df_aesa_to_cnrm_cm6_1hr[columns].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87984bd",
   "metadata": {},
   "source": [
    "## 3.3. Base de Dados GCM para Predição (Inutilizado)\n",
    "\n",
    "```shell\n",
    "O processo consiste em criar uma base de dados com os mesmos \n",
    "pontos da base de dados locais, para que assim se possa realizar \n",
    "a interpolação da precipitação do GCM para esses pontos.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127ad96",
   "metadata": {},
   "source": [
    "### 3.3.1. Configurando Base de Dados do GCM para Predição\n",
    "\n",
    "```python\n",
    "# Geração ou abertura de base de dados gerada\n",
    "if databases_generate == True:\n",
    "\n",
    "    # Definindo base de dados\n",
    "    df_cnrm_cm6_1hr_to_aesa = complete_temporal_series(df_aesa, 'lat', 'lon', [i for i in range(1994, 2024)])\n",
    "\n",
    "    # Cria uma coluna \"pnt\" que combina latitude e longitude como string separada por ponto e vírgula\n",
    "    df_cnrm_cm6_1hr_to_aesa['pnt'] = df_cnrm_cm6_1hr_to_aesa[\"lat\"].astype(str) + \";\" + df_cnrm_cm6_1hr_to_aesa[\"lon\"].astype(str)\n",
    "\n",
    "    # Exportando base de dados gerada\n",
    "    df_cnrm_cm6_1hr_to_aesa.to_csv(f'cnrm_cm6_1hr_to_aesa_{database_type}.csv')\n",
    "\n",
    "else:\n",
    "\n",
    "    # Abrindo base de dados\n",
    "    df_cnrm_cm6_1hr_to_aesa = pd.read_csv(f'cnrm_cm6_1hr_to_aesa_{database_type}.csv')\n",
    "\n",
    "# Informaões da base de dados gerada\n",
    "df_cnrm_cm6_1hr_to_aesa.info()\n",
    "```\n",
    "\n",
    "#### 3.3.2. Configurando Base de Dados de GCM para Predição com IDW\n",
    "\n",
    "```python\n",
    "# Caso não tenha a coluna IDW nas \"colunas_de_interesse\", calcula-se o IDW\n",
    "if idw_method == True:\n",
    "\n",
    "    if idw_generate == True:  # 97m 54.1s\n",
    "        \n",
    "        # Adicionando coluna IDW à base de dados\n",
    "\n",
    "        df_temp = pd.DataFrame()\n",
    "\n",
    "        for _, row in df_cnrm_cm6_1hr_to_aesa.iterrows():   \n",
    "\n",
    "            row_temp = interpolacao_por_idw(pd.concat([df_cnrm_cm6_1hr, pd.DataFrame([row])], ignore_index=True), \"pr\", \"ano\", \"mes\", \"pnt\", row['pnt'], False)\n",
    "            \n",
    "            df_temp = pd.concat([df_temp, row_temp[row_temp['pnt'] == row['pnt']]], ignore_index=True)\n",
    "\n",
    "            print(porcentagem_em_barra(_+1, len(df_cnrm_cm6_1hr_to_aesa)))\n",
    "\n",
    "        df_temp.to_csv(f'cnrm_cm6_1hr_to_aesa_{database_type}_idw.csv')\n",
    "\n",
    "        df_cnrm_cm6_1hr_to_aesa = df_temp.copy()\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Abrindo base de dados\n",
    "        df_cnrm_cm6_1hr_to_aesa = pd.read_csv(f'cnrm_cm6_1hr_to_aesa_{database_type}_idw.csv')\n",
    "\n",
    "# Informaões da base de dados gerada\n",
    "df_cnrm_cm6_1hr_to_aesa.info()\n",
    "```\n",
    "\n",
    "#### 3.3.3. Configurando Modelo Preditivo de Interpolação\n",
    "\n",
    "```python\n",
    "# Definindo colunas para treino\n",
    "if idw_method == True:\n",
    "    columns_X = [\"lat\", \"lon\", \"ano\", \"mes\", \"IDW\"]\n",
    "else:\n",
    "    columns_X = [\"lat\", \"lon\", \"ano\", \"mes\"]\n",
    "\n",
    "# Escolhendo melhor modelo preditivo\n",
    "model = interpolacao_por_ml(df_cnrm_cm6_1hr, columns_X, \"pr\", \"pnt\", 5)\n",
    "\n",
    "# Definindo features (X) e variável alvo (y)\n",
    "X = df_cnrm_cm6_1hr[columns_X].copy()\n",
    "y = df_cnrm_cm6_1hr[\"pr\"].copy()\n",
    "\n",
    "# Treinamento\n",
    "model.fit(X, y)\n",
    "```\n",
    "\n",
    "```python\n",
    "# Previsão dos valores de 'pr' com o modelo treinado\n",
    "pr = model.predict(df_cnrm_cm6_1hr_to_aesa[columns_X])\n",
    "\n",
    "# Colunas do Modelo\n",
    "columns = ['lat', 'lon', 'ano', 'mes', 'pr']\n",
    "\n",
    "# Adicionando a nova coluna 'pr' ao DataFrame\n",
    "df_cnrm_cm6_1hr_to_aesa['pr'] = pr\n",
    "\n",
    "# Salvando dados preditos\n",
    "df_cnrm_cm6_1hr_to_aesa[columns].to_csv(f'3-INTERPOLACAO/3.2/3.2.3/3.2.3.3/cnrm_cm6_1hr_to_aesa_{database_type}.csv')\n",
    "\n",
    "# Exibindo as primeiras linhas para verificar\n",
    "df_cnrm_cm6_1hr_to_aesa[columns].info()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
