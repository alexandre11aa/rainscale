{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd4f9542",
   "metadata": {},
   "source": [
    "# 3. Espacialização de Dados Locais para Pontos do CMIP6\n",
    "\n",
    "```python\n",
    "Esse caderno tem como objetivo a obtenção da precipitação de dados locais \n",
    "para os pontos definidos nos GCMs do CMIP6 a partir de interpolação espacial.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b45bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor\n",
    ")\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd9789",
   "metadata": {},
   "source": [
    "## 3.1 Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f094f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de se vai ocorrer ou não a geração de bases de dados\n",
    "databases_generate = True\n",
    "\n",
    "# Definição de se vai ocorrer ou não o a geração e o uso do método IDW\n",
    "idw_method = True\n",
    "idw_generate = False\n",
    "\n",
    "# Tipo de base de dados local utilizada ('sum' ou 'max')\n",
    "database_type = 'sum'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73232c",
   "metadata": {},
   "source": [
    "## 3.2 Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f405034d",
   "metadata": {},
   "source": [
    "### 3.1.1. Função para Limeza de Terminal e Células"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0db8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear():\n",
    "    '''\n",
    "    Função para limpar terminal ou célula\n",
    "    '''\n",
    "\n",
    "    # Limpando terminal\n",
    "    os.system('cls')\n",
    "\n",
    "    # Limpando célula\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f245d",
   "metadata": {},
   "source": [
    "### 3.1.2. Função que Adiciona coluna IDW à Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44ddef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def porcentagem_em_barra(valor_atual: int,\n",
    "                         valor_total: int) -> str:\n",
    "    \"\"\"\n",
    "    Gerador de barra de porcentagem a partir de valor atual e total.\n",
    "    \"\"\"\n",
    "\n",
    "    porcentagem = 100 * (valor_atual / valor_total)\n",
    "\n",
    "    completo   = '-' * (int(porcentagem))\n",
    "    incompleto = '_' * (100 - int(porcentagem))\n",
    "\n",
    "    situacao = f'[{completo}{incompleto}] {porcentagem:.2f}% ({valor_atual} de {valor_total})'\n",
    "\n",
    "    return situacao\n",
    "\n",
    "def vizinhos_proximos(lat: float,\n",
    "                      lon: float,\n",
    "                      lat_lon: list[str],\n",
    "                      n_vizinhos: int = 5):\n",
    "    \"\"\"\n",
    "    Gerador de lista de pontos vizinhos próximos de determinado ponto.\n",
    "\n",
    "    Args:\n",
    "        lat (float): Latitude do ponto principal;\n",
    "        lon (float): Logitude do ponto principal;\n",
    "        lat_lon (list[str]): Lista com latitudes e longitudes de pontos próximos ao ponto principal;\n",
    "        n_vizinhos (int, optional): Números de pontos vizinhos ao ponto principal a se estimar.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de n pontos mais próximos ao ponto principal.\n",
    "    \"\"\"\n",
    "\n",
    "    # Lista para armazenar tuplas (string_original, distancia)\n",
    "    distancias = []\n",
    "\n",
    "    for ponto_str in lat_lon:\n",
    "        lat_p, lon_p = map(float, ponto_str.split(\";\"))\n",
    "        dist = np.linalg.norm(np.array([lat, lon]) - np.array([lat_p, lon_p]))\n",
    "        distancias.append((ponto_str, dist))\n",
    "\n",
    "    # Ordena pela menor distância\n",
    "    distancias_ordenadas = sorted(distancias, key=lambda x: x[1])\n",
    "\n",
    "    # Pega os n vizinhos mais próximos (ignorando o primeiro se for o próprio ponto)\n",
    "    vizinhos = [p[0] for p in distancias_ordenadas if p[1] != 0][:n_vizinhos]\n",
    "\n",
    "    return vizinhos\n",
    "\n",
    "def interpolacao_por_idw(df: pd.DataFrame,\n",
    "                         var_de_predicao: str,\n",
    "                         var_de_anos: str,\n",
    "                         var_de_meses: str,\n",
    "                         var_de_pontos: str,\n",
    "                         pontos: str = 'all',\n",
    "                         progresso: bool = True,\n",
    "                         constante: int = 2,\n",
    "                         n_vizinhos: int = 5) -> list:\n",
    "    '''\n",
    "    Interpola dados de séries temporais a partir do método IDW, e cria uma coluna para tal\n",
    "    '''\n",
    "\n",
    "    # Definindo nova coluna para o IDW\n",
    "    df.loc[:, 'IDW'] = np.nan\n",
    "\n",
    "    # Obtendo pontos únicos\n",
    "    if pontos == 'all':\n",
    "        pontos_unicos = df[var_de_pontos].unique()\n",
    "    else:\n",
    "        pontos_unicos = [pontos]\n",
    "\n",
    "    # Varendo pontos únicos\n",
    "    for i, ponto in enumerate(pontos_unicos):\n",
    "\n",
    "        if progresso == True:\n",
    "\n",
    "            # Ponto em cálculo\n",
    "            print(porcentagem_em_barra(i+1, len(pontos_unicos)))\n",
    "\n",
    "        lat, lon = map(float, ponto.split(\";\"))\n",
    "\n",
    "        # Obtendo anos únicos\n",
    "        anos_unicos = df[df[var_de_pontos] == ponto][var_de_anos].unique()\n",
    "\n",
    "        # Varendo anos únicos dos pontos únicos\n",
    "        for ano in anos_unicos:\n",
    "\n",
    "            # Obtendo meses únicos\n",
    "            meses_unicos = df[(df[var_de_pontos] == ponto) &\n",
    "                              (df[var_de_anos] == ano)][var_de_meses].unique()\n",
    "\n",
    "            # Varrendo meses únicos dos anos únicos dos pontos únicos\n",
    "            for mes in meses_unicos:\n",
    "\n",
    "                # Filtrando pontos unicos que possuem mesmo mes e ano que o ponto em varredura\n",
    "                pontos_unicos_filtrados = df[(df[var_de_anos] == ano) &\n",
    "                                             (df[var_de_meses] == mes)][var_de_pontos].unique()\n",
    "\n",
    "                # Obtendo pontos vizinhos mais próximos do ponto em varredura\n",
    "                vizinhos = vizinhos_proximos(lat, lon, pontos_unicos_filtrados, n_vizinhos)\n",
    "\n",
    "                # Definindo variáveis para calcular IDW\n",
    "                dividendo = divisor = 0\n",
    "\n",
    "                for ponto_vizinho in vizinhos:\n",
    "\n",
    "                    lat_vizinha, lon_vizinha = map(float, ponto_vizinho.split(\";\"))\n",
    "\n",
    "                    distancia = ((lat - lat_vizinha)**2 + (lon - lon_vizinha)**2)**(1/2)\n",
    "\n",
    "                    variavel = df.loc[(df[var_de_pontos] == ponto_vizinho) &\n",
    "                                      (df[var_de_anos] == ano) &\n",
    "                                      (df[var_de_meses] == mes), var_de_predicao]\n",
    "\n",
    "                    if not variavel.empty:\n",
    "                        valor = variavel.iloc[0]\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    dividendo += valor / (distancia**constante)\n",
    "\n",
    "                    divisor += 1 / (distancia**constante)\n",
    "\n",
    "                if divisor == 0:\n",
    "                    idw = np.nan\n",
    "                else:\n",
    "                    idw = dividendo / divisor\n",
    "\n",
    "                idx = df.loc[(df[var_de_pontos] == ponto) &\n",
    "                             (df[var_de_anos] == ano) &\n",
    "                             (df[var_de_meses] == mes), 'IDW'].index[0]\n",
    "\n",
    "                df.at[idx, 'IDW'] = idw\n",
    "\n",
    "        clear()\n",
    "\n",
    "    df['IDW'] = df['IDW'].fillna(df['IDW'].mean())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6709bccb",
   "metadata": {},
   "source": [
    "### 3.1.3. Interpolação a partir de Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e8b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolacao_por_ml(df: pd.DataFrame,\n",
    "                        col_de_treino: list[str],\n",
    "                        var_de_predicao: str,\n",
    "                        var_de_pontos: str,\n",
    "                        n_de_teste: int):\n",
    "\n",
    "    # Obtendo pontos únicos\n",
    "    pontos_unicos = df[var_de_pontos].unique()\n",
    "\n",
    "    # Definição dos modelos\n",
    "    models = [\n",
    "\n",
    "        (\"ExtraTrees\", ExtraTreesRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=20,\n",
    "            max_features=2,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            random_state=7\n",
    "        )),\n",
    "\n",
    "        (\"RandomForest\", RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=25,\n",
    "            max_features=2,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            random_state=7\n",
    "        )),\n",
    "\n",
    "        (\"KNeighbors\", KNeighborsRegressor(\n",
    "            n_neighbors=7,\n",
    "            weights='distance',\n",
    "            algorithm='auto'\n",
    "        )),\n",
    "\n",
    "        (\"GradientBoosting\", GradientBoostingRegressor(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            subsample=0.8,\n",
    "            random_state=7\n",
    "        )),\n",
    "\n",
    "        # (\"LinearRegression\", LinearRegression(\n",
    "        #     fit_intercept=True,\n",
    "        #     positive=False\n",
    "        # ))\n",
    "\n",
    "    ]\n",
    "\n",
    "    # Defininção de lista de métricas\n",
    "    metrics = []\n",
    "    for i in range(len(models)):\n",
    "        metrics.append([[], []])\n",
    "\n",
    "    for i in range(n_de_teste):\n",
    "\n",
    "        # Embaralha os pontos únicos\n",
    "        np.random.shuffle(pontos_unicos)\n",
    "\n",
    "        # Dividindo em 70% treino e 30% teste\n",
    "        split_idx = int(len(pontos_unicos) * 0.8)\n",
    "        pontos_treino = set(pontos_unicos[:split_idx])\n",
    "        pontos_teste = set(pontos_unicos[split_idx:])\n",
    "\n",
    "        # Criando DataFrames de treino e teste\n",
    "        df_treino = df[df[var_de_pontos].isin(pontos_treino)].copy()\n",
    "        df_teste = df[df[var_de_pontos].isin(pontos_teste)].copy()\n",
    "\n",
    "        # Definindo features (X) e variável alvo (y)\n",
    "        X_train = df_treino[col_de_treino]\n",
    "        y_train = df_treino[var_de_predicao]\n",
    "\n",
    "        X_test = df_teste[col_de_treino]\n",
    "        y_test = df_teste[var_de_predicao]\n",
    "\n",
    "        # Treinar e avaliar cada modelo\n",
    "        for j in range(len(models)):\n",
    "            models[j][1].fit(X_train, y_train)                                 # Treinamento\n",
    "            y_pred = models[j][1].predict(X_test)                              # Previsão\n",
    "            metrics[j][0].append(r2_score(y_test, y_pred))                     # R²\n",
    "            metrics[j][1].append(np.sqrt(mean_squared_error(y_test, y_pred)))  # RMSE\n",
    "\n",
    "    # Verificando melhor Modelo a partir de r2\n",
    "    best_model = (0, '', '')\n",
    "\n",
    "    print('Verificação de Modelos:\\n')\n",
    "\n",
    "    for i in range(len(metrics)):\n",
    "\n",
    "        r2, rmse = np.mean(metrics[i][0]), np.mean(metrics[i][1])\n",
    "\n",
    "        if best_model[0] < r2:\n",
    "            best_model = r2, models[i][0], models[i][1]\n",
    "\n",
    "        print(f'Modelo: {models[i][0][:3]} \\t R²: {r2:.4f} \\t RMSE: {rmse:.4f}')\n",
    "\n",
    "    print(f'\\nO melhor modelo de ML para a base de dados é: {best_model[1]}.')\n",
    "\n",
    "    return best_model[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96757be9",
   "metadata": {},
   "source": [
    "### 3.1.4. Interpolação a partir de Modelo de Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87debf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolacao_por_cnn(df: pd.DataFrame,\n",
    "                         col_de_treino: list[str],\n",
    "                         var_de_predicao: str,\n",
    "                         var_de_pontos: str,\n",
    "                         n_de_teste: int):\n",
    "\n",
    "    # Pontos únicos\n",
    "    pontos_unicos = df[var_de_pontos].unique()\n",
    "\n",
    "    # Listas para métricas\n",
    "    r2_list = []\n",
    "    rmse_list = []\n",
    "\n",
    "    for i in range(n_de_teste):\n",
    "\n",
    "        np.random.shuffle(pontos_unicos)\n",
    "        split_idx = int(len(pontos_unicos) * 0.8)\n",
    "\n",
    "        pontos_treino = set(pontos_unicos[:split_idx])\n",
    "        pontos_teste = set(pontos_unicos[split_idx:])\n",
    "\n",
    "        df_treino = df[df[var_de_pontos].isin(pontos_treino)].copy()\n",
    "        df_teste = df[df[var_de_pontos].isin(pontos_teste)].copy()\n",
    "\n",
    "        # Definindo X e y\n",
    "        X_train = df_treino[col_de_treino].values\n",
    "        y_train = df_treino[var_de_predicao].values\n",
    "\n",
    "        X_test = df_teste[col_de_treino].values\n",
    "        y_test = df_teste[var_de_predicao].values\n",
    "\n",
    "        # Redimensionar para 3D: (samples, timesteps=1, features)\n",
    "        X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "        # Limpar sessão anterior (importante em loops com Keras)\n",
    "        clear_session()\n",
    "\n",
    "        # Criando modelo CNN\n",
    "        cnn = Sequential([\n",
    "            Input(shape=(1, X_train.shape[2])),\n",
    "            Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "            MaxPooling1D(1),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "\n",
    "        cnn.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mse'])\n",
    "\n",
    "        # Treinamento\n",
    "        cnn.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
    "\n",
    "        # Previsão e avaliação\n",
    "        y_pred = cnn.predict(X_test).flatten()\n",
    "\n",
    "        r2_list.append(r2_score(y_test, y_pred))\n",
    "        rmse_list.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    # Resultados finais\n",
    "    print(f\"\\nCNN \\t Média R²: {np.mean(r2_list):.4f} \\t Média RMSE: {np.mean(rmse_list):.4f}\")\n",
    "\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed6cfe3",
   "metadata": {},
   "source": [
    "### 3.1.5. Preenchimento para Serie Temporal Completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "423c4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_temporal_series(df: pd.DataFrame,\n",
    "                             lat_col: str,\n",
    "                             lon_col: str,\n",
    "                             anos: list) -> pd.DataFrame:\n",
    "    '''\n",
    "    Preenchimento de datas faltantes em séries temporais\n",
    "    '''\n",
    "\n",
    "    # Obtendo pontos de lat lon únicos\n",
    "    df_pontos_unicos = df[[lat_col, lon_col]].drop_duplicates().reset_index().drop(columns=[\"index\"])\n",
    "\n",
    "    # Obtendo meses e anos da base de dados\n",
    "    df_anos_meses = pd.DataFrame([(ano, mes) for ano in anos for mes in range(1, 13)], columns=[\"ano\", \"mes\"])\n",
    "\n",
    "    # Fazendo produto cartesiano entre pontos e anos/meses\n",
    "    df_pontos_unicos['key'] = 1\n",
    "    df_anos_meses['key'] = 1\n",
    "\n",
    "    # Unindo pontos e anos/meses\n",
    "    df_expandido = pd.merge(df_pontos_unicos, df_anos_meses, on='key').drop(columns='key')\n",
    "\n",
    "    # Cria um DataFrame vazio para armazenar os dados expandidos\n",
    "    return df_expandido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bcb420",
   "metadata": {},
   "source": [
    "## 3.2. Coluna IDW para dados da AESA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f513bf8",
   "metadata": {},
   "source": [
    "### 3.2.1. Configurando Bases de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e267a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Informações Locais:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87120 entries, 0 to 87119\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0.1  87120 non-null  int64  \n",
      " 1   Unnamed: 0    87120 non-null  int64  \n",
      " 2   lat           87120 non-null  float64\n",
      " 3   lon           87120 non-null  float64\n",
      " 4   alt           87120 non-null  float64\n",
      " 5   bac           87120 non-null  object \n",
      " 6   ano           87120 non-null  int64  \n",
      " 7   mes           87120 non-null  int64  \n",
      " 8   pr_local      87120 non-null  float64\n",
      " 9   pnt           87120 non-null  object \n",
      " 10  IDW           87120 non-null  float64\n",
      "dtypes: float64(5), int64(4), object(2)\n",
      "memory usage: 7.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Base de dados local de acumulados\n",
    "df_aesa = pd.read_csv(\n",
    "    f\"../datas/interim/2.3.1_aesa_database_create/aesa_1994-2023_mon_{database_type}.csv\"\n",
    ")\n",
    "\n",
    "# Caso não tenha a coluna IDW nas \"colunas_de_interesse\", calcula-se o IDW\n",
    "if idw_method == True:\n",
    "\n",
    "    if idw_generate == True:  # 115m 33.8s\n",
    "\n",
    "        # Local\n",
    "        df_aesa = interpolacao_por_idw(df_aesa, \"pr_local\", \"ano\", \"mes\", \"pnt\")\n",
    "        df_aesa.to_csv(f'../datas/interim/3.2.1_aesa_with_idw/aesa_1994-2023_mon_{database_type}_idw.csv')\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Local\n",
    "        df_aesa = pd.read_csv(f'../datas/interim/3.2.1_aesa_with_idw/aesa_1994-2023_mon_{database_type}_idw.csv')\n",
    "\n",
    "# Visualizando Bases de Dados Locais\n",
    "print('- Informações Locais:')\n",
    "print(df_aesa.info())\n",
    "# grafico_de_pontos(df_aesa, \"lat\", \"lon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862258f5",
   "metadata": {},
   "source": [
    "## 3.3. Base de Dados Local para Predição\n",
    "\n",
    "```python\n",
    "O processo consiste em criar uma base de dados com os mesmos \n",
    "pontos da base de dados do GCM, para que assim se possa realizar \n",
    "a interpolação da precipitação local para esses pontos.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9afb457",
   "metadata": {},
   "source": [
    "### 3.3.1. Configurando Base de Dados Local para Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "949ad7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   lat     18000 non-null  float64\n",
      " 1   lon     18000 non-null  float64\n",
      " 2   ano     18000 non-null  int64  \n",
      " 3   mes     18000 non-null  int64  \n",
      " 4   pnt     18000 non-null  object \n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 703.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Geração ou abertura de base de dados gerada\n",
    "if databases_generate == True:\n",
    "\n",
    "    # Definindo base de dados de GCM\n",
    "    df_cnrm_cm6_1hr = pd.read_csv(\n",
    "        f\"../datas/interim/1.3.2_cmip6_database_create/pr_day_CNRM-CM6-1-HR_ssp585_r1i1p1f2_gr_19940101-21001231_{database_type}.csv\"\n",
    "    )\n",
    "\n",
    "    # Definindo base de dados\n",
    "    df_aesa_to_cnrm_cm6_1hr = complete_temporal_series(df_cnrm_cm6_1hr, 'lat', 'lon', [i for i in range(1994, 2024)])\n",
    "\n",
    "    # Cria uma coluna \"pnt\" que combina latitude e longitude como string separada por ponto e vírgula\n",
    "    df_aesa_to_cnrm_cm6_1hr['pnt'] = df_aesa_to_cnrm_cm6_1hr[\"lat\"].astype(str) + \";\" + df_aesa_to_cnrm_cm6_1hr[\"lon\"].astype(str)\n",
    "\n",
    "    # Exportando base de dados gerada\n",
    "    df_aesa_to_cnrm_cm6_1hr.to_csv(f'../datas/interim/3.3.1_aesa_in_cmip6_points/aesa_to_cnrm_cm6_1hr_{database_type}.csv')\n",
    "\n",
    "else:\n",
    "\n",
    "    # Abrindo base de dados\n",
    "    df_aesa_to_cnrm_cm6_1hr = pd.read_csv(f'../datas/interim/3.3.1_aesa_in_cmip6_points/aesa_to_cnrm_cm6_1hr_{database_type}.csv')\n",
    "\n",
    "# Informaões da base de dados gerada\n",
    "df_aesa_to_cnrm_cm6_1hr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23e461",
   "metadata": {},
   "source": [
    "### 3.3.2. Configurando Base de Dados Local para Predição com IDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04979478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0.1  18000 non-null  int64  \n",
      " 1   Unnamed: 0    0 non-null      float64\n",
      " 2   lat           18000 non-null  float64\n",
      " 3   lon           18000 non-null  float64\n",
      " 4   alt           0 non-null      float64\n",
      " 5   bac           0 non-null      float64\n",
      " 6   ano           18000 non-null  int64  \n",
      " 7   mes           18000 non-null  int64  \n",
      " 8   pr_local      0 non-null      float64\n",
      " 9   pnt           18000 non-null  object \n",
      " 10  IDW           18000 non-null  float64\n",
      "dtypes: float64(7), int64(3), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Caso não tenha a coluna IDW nas \"colunas_de_interesse\", calcula-se o IDW\n",
    "if idw_method == True:\n",
    "\n",
    "    if idw_generate == True:  # 25m 35.1s\n",
    "\n",
    "        # Adicionando coluna IDW à base de dados\n",
    "\n",
    "        df_temp = pd.DataFrame()\n",
    "\n",
    "        for _, row in df_aesa_to_cnrm_cm6_1hr.iterrows():\n",
    "\n",
    "            row_temp = interpolacao_por_idw(pd.concat([df_aesa, pd.DataFrame([row])], ignore_index=True), \"pr_local\", \"ano\", \"mes\", \"pnt\", row['pnt'], False)\n",
    "\n",
    "            df_temp = pd.concat([df_temp, row_temp[row_temp['pnt'] == row['pnt']]], ignore_index=True)\n",
    "\n",
    "            print(porcentagem_em_barra(_+1, len(df_aesa_to_cnrm_cm6_1hr)))\n",
    "\n",
    "        df_temp.to_csv(f'../datas/interim/3.3.2_aesa_in_cmip6_points_with_idw/aesa_to_cnrm_cm6_1hr_{database_type}_idw.csv')\n",
    "\n",
    "        df_aesa_to_cnrm_cm6_1hr = df_temp.copy()\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Abrindo base de dados\n",
    "        df_aesa_to_cnrm_cm6_1hr = pd.read_csv(f'../datas/interim/3.3.2_aesa_in_cmip6_points_with_idw/aesa_to_cnrm_cm6_1hr_{database_type}_idw.csv')\n",
    "\n",
    "# Informaões da base de dados gerada\n",
    "df_aesa_to_cnrm_cm6_1hr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc13927",
   "metadata": {},
   "source": [
    "#### 3.3.3. Configurando Modelo Preditivo de Interpolação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6a464f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificação de Modelos:\n",
      "\n",
      "Modelo: Ext \t R²: 0.7826 \t RMSE: 37.5774\n",
      "Modelo: Ran \t R²: 0.7721 \t RMSE: 38.4632\n",
      "Modelo: KNe \t R²: 0.7517 \t RMSE: 40.1451\n",
      "Modelo: Gra \t R²: 0.7712 \t RMSE: 38.5478\n",
      "\n",
      "O melhor modelo de ML para a base de dados é: ExtraTrees.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesRegressor(max_depth=20, max_features=2, n_estimators=200,\n",
       "                    random_state=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ExtraTreesRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html\">?<span>Documentation for ExtraTreesRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesRegressor(max_depth=20, max_features=2, n_estimators=200,\n",
       "                    random_state=7)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesRegressor(max_depth=20, max_features=2, n_estimators=200,\n",
       "                    random_state=7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo colunas para treino\n",
    "if idw_method == True:\n",
    "    columns_X = [\"lat\", \"lon\", \"ano\", \"mes\", \"IDW\"]\n",
    "else:\n",
    "    columns_X = [\"lat\", \"lon\", \"ano\", \"mes\"]\n",
    "\n",
    "# Escolhendo melhor modelo preditivo de ML\n",
    "model = interpolacao_por_ml(df_aesa, columns_X, \"pr_local\", \"pnt\", 5)\n",
    "\n",
    "# # Escolhendo melhor modelo preditivo de DL\n",
    "# model = interpolacao_por_cnn(df_aesa, columns_X, \"pr_local\", \"pnt\", 5)\n",
    "\n",
    "# Definindo features (X) e variável alvo (y)\n",
    "X = df_aesa[columns_X].copy()\n",
    "y = df_aesa[\"pr_local\"].copy()\n",
    "\n",
    "# Treinamento\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a14df54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   lat       18000 non-null  float64\n",
      " 1   lon       18000 non-null  float64\n",
      " 2   ano       18000 non-null  int64  \n",
      " 3   mes       18000 non-null  int64  \n",
      " 4   pr_local  18000 non-null  float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 703.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Previsão dos valores de 'pr_local' com o modelo treinado\n",
    "pr_local = model.predict(df_aesa_to_cnrm_cm6_1hr[columns_X])\n",
    "\n",
    "# Colunas do Modelo\n",
    "columns = ['lat', 'lon', 'ano', 'mes', 'pr_local']\n",
    "\n",
    "# Adicionando a nova coluna 'pr_local' ao DataFrame\n",
    "df_aesa_to_cnrm_cm6_1hr['pr_local'] = pr_local\n",
    "\n",
    "# Salvando dados preditos\n",
    "df_aesa_to_cnrm_cm6_1hr[columns].to_csv(f'../datas/interim/3.3.3_aesa_interpolated_to_cmip6/aesa_to_cnrm_cm6_1hr_{database_type}_interpolated.csv')\n",
    "\n",
    "# Exibindo as primeiras linhas para verificar\n",
    "df_aesa_to_cnrm_cm6_1hr[columns].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87984bd",
   "metadata": {},
   "source": [
    "## 3.3. Base de Dados GCM para Predição (Inutilizado)\n",
    "\n",
    "```shell\n",
    "O processo consiste em criar uma base de dados com os mesmos \n",
    "pontos da base de dados locais, para que assim se possa realizar \n",
    "a interpolação da precipitação do GCM para esses pontos.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127ad96",
   "metadata": {},
   "source": [
    "### 3.3.1. Configurando Base de Dados do GCM para Predição\n",
    "\n",
    "```python\n",
    "# Geração ou abertura de base de dados gerada\n",
    "if databases_generate == True:\n",
    "\n",
    "    # Definindo base de dados\n",
    "    df_cnrm_cm6_1hr_to_aesa = complete_temporal_series(df_aesa, 'lat', 'lon', [i for i in range(1994, 2024)])\n",
    "\n",
    "    # Cria uma coluna \"pnt\" que combina latitude e longitude como string separada por ponto e vírgula\n",
    "    df_cnrm_cm6_1hr_to_aesa['pnt'] = df_cnrm_cm6_1hr_to_aesa[\"lat\"].astype(str) + \";\" + df_cnrm_cm6_1hr_to_aesa[\"lon\"].astype(str)\n",
    "\n",
    "    # Exportando base de dados gerada\n",
    "    df_cnrm_cm6_1hr_to_aesa.to_csv(f'cnrm_cm6_1hr_to_aesa_{database_type}.csv')\n",
    "\n",
    "else:\n",
    "\n",
    "    # Abrindo base de dados\n",
    "    df_cnrm_cm6_1hr_to_aesa = pd.read_csv(f'cnrm_cm6_1hr_to_aesa_{database_type}.csv')\n",
    "\n",
    "# Informaões da base de dados gerada\n",
    "df_cnrm_cm6_1hr_to_aesa.info()\n",
    "```\n",
    "\n",
    "#### 3.3.2. Configurando Base de Dados de GCM para Predição com IDW\n",
    "\n",
    "```python\n",
    "# Caso não tenha a coluna IDW nas \"colunas_de_interesse\", calcula-se o IDW\n",
    "if idw_method == True:\n",
    "\n",
    "    if idw_generate == True:  # 97m 54.1s\n",
    "        \n",
    "        # Adicionando coluna IDW à base de dados\n",
    "\n",
    "        df_temp = pd.DataFrame()\n",
    "\n",
    "        for _, row in df_cnrm_cm6_1hr_to_aesa.iterrows():   \n",
    "\n",
    "            row_temp = interpolacao_por_idw(pd.concat([df_cnrm_cm6_1hr, pd.DataFrame([row])], ignore_index=True), \"pr\", \"ano\", \"mes\", \"pnt\", row['pnt'], False)\n",
    "            \n",
    "            df_temp = pd.concat([df_temp, row_temp[row_temp['pnt'] == row['pnt']]], ignore_index=True)\n",
    "\n",
    "            print(porcentagem_em_barra(_+1, len(df_cnrm_cm6_1hr_to_aesa)))\n",
    "\n",
    "        df_temp.to_csv(f'cnrm_cm6_1hr_to_aesa_{database_type}_idw.csv')\n",
    "\n",
    "        df_cnrm_cm6_1hr_to_aesa = df_temp.copy()\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Abrindo base de dados\n",
    "        df_cnrm_cm6_1hr_to_aesa = pd.read_csv(f'cnrm_cm6_1hr_to_aesa_{database_type}_idw.csv')\n",
    "\n",
    "# Informaões da base de dados gerada\n",
    "df_cnrm_cm6_1hr_to_aesa.info()\n",
    "```\n",
    "\n",
    "#### 3.3.3. Configurando Modelo Preditivo de Interpolação\n",
    "\n",
    "```python\n",
    "# Definindo colunas para treino\n",
    "if idw_method == True:\n",
    "    columns_X = [\"lat\", \"lon\", \"ano\", \"mes\", \"IDW\"]\n",
    "else:\n",
    "    columns_X = [\"lat\", \"lon\", \"ano\", \"mes\"]\n",
    "\n",
    "# Escolhendo melhor modelo preditivo\n",
    "model = interpolacao_por_ml(df_cnrm_cm6_1hr, columns_X, \"pr\", \"pnt\", 5)\n",
    "\n",
    "# Definindo features (X) e variável alvo (y)\n",
    "X = df_cnrm_cm6_1hr[columns_X].copy()\n",
    "y = df_cnrm_cm6_1hr[\"pr\"].copy()\n",
    "\n",
    "# Treinamento\n",
    "model.fit(X, y)\n",
    "```\n",
    "\n",
    "```python\n",
    "# Previsão dos valores de 'pr' com o modelo treinado\n",
    "pr = model.predict(df_cnrm_cm6_1hr_to_aesa[columns_X])\n",
    "\n",
    "# Colunas do Modelo\n",
    "columns = ['lat', 'lon', 'ano', 'mes', 'pr']\n",
    "\n",
    "# Adicionando a nova coluna 'pr' ao DataFrame\n",
    "df_cnrm_cm6_1hr_to_aesa['pr'] = pr\n",
    "\n",
    "# Salvando dados preditos\n",
    "df_cnrm_cm6_1hr_to_aesa[columns].to_csv(f'3-INTERPOLACAO/3.2/3.2.3/3.2.3.3/cnrm_cm6_1hr_to_aesa_{database_type}.csv')\n",
    "\n",
    "# Exibindo as primeiras linhas para verificar\n",
    "df_cnrm_cm6_1hr_to_aesa[columns].info()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
